# Step 1: Local Models Guide (LM Studio)

## Overview
This guide helps you complete Step 1: experimenting with local models using LM Studio.

## Installation Steps

1. **Download LM Studio**
   - Visit: https://lmstudio.ai
   - Download for your OS (macOS/Windows/Linux)
   - Install the application

2. **Download Models**
   - Open LM Studio
   - Navigate to the "Search" or "Models" tab
   - Search for and download:
     - `gemma3-4b-it` (or `gemma-2-2b-it`)
     - `llama-3.2-3b-instruct`
   - Wait for downloads to complete

## Testing Checklist

### Model 1: Gemma
- [ ] Load `gemma3-4b-it` model
- [ ] Test with text file upload
- [ ] Test with image upload
- [ ] Try different prompt types:
  - [ ] Direct question
  - [ ] Creative writing prompt
  - [ ] Code generation prompt
  - [ ] Analysis prompt
- [ ] Document responses

### Model 2: Llama
- [ ] Load `llama-3.2-3b-instruct` model
- [ ] Test with text file upload
- [ ] Test with image upload
- [ ] Try same prompt types as Gemma
- [ ] Document responses

## Comparison Notes

Create a comparison document noting:
- Response quality differences
- Speed differences
- Context understanding
- Image processing capabilities
- Prompt sensitivity

## Test Files to Prepare

1. **Text File**: Create a sample document (e.g., technical documentation, article)
2. **Image File**: Prepare a test image (e.g., diagram, photo with text)

## Expected Outcomes

- Understanding of local model capabilities
- Comparison between two different models
- Insights into prompt engineering
- Documentation of findings

